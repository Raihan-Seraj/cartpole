- It happened what I expected.

- Further work:
    - Test claims (a bit strong wording?) of OA paper in an actually finite
      environment with their exact conditions.
    - Maybe try the methods used to tame the learner in the paper to these
      learners and see what happens. Do they become less biased?
        - Run for longer time. See how the bias develops.
        - Probabilistic interruptions.
    - Improved methodology: Don't count lefts and rights, but average (and also
      standard deviation) over xs. Then if we get significantly shifted average,
      we know that it's biased.
    - Try out other agents. Try to make agents that are safely interruptible and
      see whether they really are.
