[1] [Nick Bostrom: Superintelligence. Paths, Dangers,
Strategies](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies)

[2] [Nate Soares, Benja Fallenstein, Eliezer Yudkowsky, Stuart Armstrong:
Corrigibility](https://intelligence.org/files/Corrigibility.pdf)

[3] [Laurent Orseau, Stuart Armstrong: Safely Interruptible
Agents](https://intelligence.org/files/Interruptibility.pdf)

[4] [George Konidaris, Sarah Osentoski, Philip Thomas: Value Function
Approximation in Reinforcement Learning using the Fourier
Basis](http://lis.csail.mit.edu/pubs/konidaris-aaai11a.pdf)

[5] [William Dabney, Andrew Barto: Adaptive Step-Size for Online Temporal
Difference Learning](http://people.cs.umass.edu/~wdabney/papers/alphaBounds.pdf)

[6] [Nate Soares, Benya Fallenstein: Agent Foundations for Aligning Machine
Intelligence with Human Interests. A Technical Research
Agenda](https://intelligence.org/files/TechnicalAgenda.pdf)

[7] [Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman,
Dan Man√©: Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)

[8] [Jessica Taylor, Eliezer Yudkowsky, Patrick LaVictoire, Andrew Critch:
Alignment for Advanced Machine Learning
Systems](https://intelligence.org/2016/07/27/alignment-machine-learning/)

[9] Richard Sutton, Andrew G. Barto: Reinforcement Learning: An Introduction.
Draft of the 2nd ed. from October 2015.
